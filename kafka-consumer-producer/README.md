# Scripts Kafka Consumer/Producer pour Tests Prometheus

Ce r√©pertoire contient deux scripts Python permettant de g√©n√©rer une charge de trafic Kafka pour tester et monitorer votre cluster Kafka avec Prometheus.

## üìã Pr√©requis

### Option 1 : Installation locale

Les scripts n√©cessitent les biblioth√®ques suivantes. Installez-les avec :

```bash
pip install -r requirements.txt
```

Ou manuellement :

```bash
pip install kafka-python confluent-kafka python-dotenv
```

**Note importante** : 
- `kafka_producer_bomber.py` utilise la biblioth√®que `kafka-python`
- `kafka_consumer_bomber.py` utilise la biblioth√®que `confluent-kafka`
- Les deux scripts utilisent `python-dotenv` pour charger les variables d'environnement depuis un fichier `.env`

### Option 2 : Utilisation avec Docker (recommand√©)

Un Dockerfile est fourni pour ex√©cuter les scripts et les outils Kafka perf test dans un conteneur Docker.

**Avantages** :
- ‚úÖ Environnement isol√© et reproductible
- ‚úÖ Inclut les outils Kafka perf test officiels
- ‚úÖ Pas besoin d'installer les d√©pendances localement
- ‚úÖ Compatible avec tous les syst√®mes d'exploitation

### Configuration Kafka

Les scripts n√©cessitent :
- Un cluster Kafka avec authentification SASL_SSL/PLAIN
- Des credentials (username/password) valides
- Acc√®s r√©seau aux brokers Kafka

### Configuration via fichier .env (recommand√©)

Pour √©viter de passer les credentials en ligne de commande, vous pouvez utiliser un fichier `.env` :

1. **Cr√©er le fichier `.env`** :
   ```bash
   cp env.example .env
   ```

2. **√âditer le fichier `.env`** avec vos param√®tres :
   ```bash
   # Param√®tres de connexion (requis)
   KAFKA_BOOTSTRAP_SERVERS=kafka1:9092,kafka2:9092
   KAFKA_USERNAME=votre_username
   KAFKA_PASSWORD=votre_password
   
   # Param√®tres de s√©curit√© (optionnels)
   KAFKA_SECURITY_PROTOCOL=SASL_SSL
   KAFKA_SASL_MECHANISM=PLAIN
   
   # Param√®tres optionnels
   KAFKA_TOPIC_PREFIX=test-prometheus
   KAFKA_NUM_TOPICS=10
   KAFKA_MESSAGES_PER_SECOND=1000
   KAFKA_NUM_THREADS=5
   KAFKA_DURATION_MINUTES=60
   ```

3. **Utiliser les scripts** sans passer les param√®tres en ligne de commande :
   ```bash
   python3 kafka_producer_bomber.py
   python3 kafka_consumer_bomber.py
   ```

**S√©curit√©** : Ajoutez `.env` √† votre `.gitignore` pour ne pas commiter vos credentials !

#### Variables d'environnement disponibles

| Variable | Description | Exemple |
|----------|-------------|---------|
| `KAFKA_BOOTSTRAP_SERVERS` | Serveurs Kafka (requis) | `kafka1:9092,kafka2:9092` |
| `KAFKA_USERNAME` | Nom d'utilisateur SASL (requis) | `admin` |
| `KAFKA_PASSWORD` | Mot de passe SASL (requis) | `secret` |
| `KAFKA_SECURITY_PROTOCOL` | Protocole de s√©curit√© | `SASL_SSL`, `SASL_PLAINTEXT`, `SSL`, `PLAINTEXT` |
| `KAFKA_SASL_MECHANISM` | M√©canisme SASL | `PLAIN`, `SCRAM-SHA-256`, `SCRAM-SHA-512` |
| `KAFKA_TOPIC_PREFIX` | Pr√©fixe des topics | `test-prometheus` |
| `KAFKA_NUM_TOPICS` | Nombre de topics | `10` |
| `KAFKA_MESSAGES_PER_SECOND` | Messages/seconde (producteur) | `1000` |
| `KAFKA_NUM_THREADS` | Nombre de threads (producteur) | `5` |
| `KAFKA_CONSUMER_GROUP` | Groupe de consommateurs | `prometheus-test-group` |
| `KAFKA_NUM_CONSUMERS` | Nombre de consommateurs | `1` |
| `KAFKA_AUTO_OFFSET_RESET` | Position de d√©part | `earliest` ou `latest` |
| `KAFKA_DURATION_MINUTES` | Dur√©e en minutes | `60` |
| `KAFKA_SSL_CAFILE` | Chemin fichier CA SSL | `/path/to/ca.pem` |
| `KAFKA_SSL_CERTFILE` | Chemin fichier certificat SSL | `/path/to/cert.pem` |
| `KAFKA_SSL_KEYFILE` | Chemin fichier cl√© SSL | `/path/to/key.pem` |
| `KAFKA_SSL_PASSWORD` | Mot de passe cl√© SSL | `key_password` |
| `KAFKA_VERBOSE` | Mode verbeux | `true` ou `false` |

**Note** : Les param√®tres pass√©s en ligne de commande ont priorit√© sur les variables d'environnement.

---

## üöÄ kafka_producer_bomber.py

### Description

Script qui g√©n√®re et envoie des messages JSON al√©atoires vers plusieurs topics Kafka. Il simule diff√©rents types de donn√©es (activit√© utilisateur, m√©triques syst√®me, transactions, logs, donn√©es de capteurs) pour cr√©er une charge r√©aliste sur le cluster.

### Utilisation

#### Commande de base

**Avec fichier .env** (recommand√©) :
```bash
python3 kafka_producer_bomber.py
```

**Sans fichier .env** :
```bash
python3 kafka_producer_bomber.py \
  --bootstrap-servers kafka1:9092,kafka2:9092 \
  --username votre_username \
  --password votre_password
```

**M√©lange .env + ligne de commande** (les arguments CLI ont priorit√©) :
```bash
python3 kafka_producer_bomber.py \
  --messages-per-second 2000 \
  --duration-minutes 30
```

#### Options disponibles (ligne de commande)

| Option | Description | D√©faut |
|--------|-------------|--------|
| `--bootstrap-servers` | **Requis** (ou via `KAFKA_BOOTSTRAP_SERVERS`). Liste des serveurs Kafka (s√©par√©s par des virgules) | Variable d'env ou - |
| `--username` | **Requis** (ou via `KAFKA_USERNAME`). Nom d'utilisateur SASL PLAIN | Variable d'env ou - |
| `--password` | **Requis** (ou via `KAFKA_PASSWORD`). Mot de passe SASL PLAIN | Variable d'env ou - |
| `--security-protocol` | Protocole de s√©curit√© (ou via `KAFKA_SECURITY_PROTOCOL`) | Variable d'env ou `SASL_SSL` |
| `--sasl-mechanism` | M√©canisme SASL (ou via `KAFKA_SASL_MECHANISM`) | Variable d'env ou `PLAIN` |
| `--topic-prefix` | Pr√©fixe des topics √† cr√©er (ou via `KAFKA_TOPIC_PREFIX`) | Variable d'env ou `test-prometheus` |
| `--num-topics` | Nombre de topics √† utiliser (ou via `KAFKA_NUM_TOPICS`) | Variable d'env ou `10` |
| `--messages-per-second` | Messages par seconde (ou via `KAFKA_MESSAGES_PER_SECOND`) | Variable d'env ou `1000` |
| `--num-threads` | Nombre de threads producteurs (ou via `KAFKA_NUM_THREADS`) | Variable d'env ou `5` |
| `--duration-minutes` | Dur√©e en minutes (ou via `KAFKA_DURATION_MINUTES`) | Variable d'env ou `60` |
| `--verbose` | Mode verbeux (ou via `KAFKA_VERBOSE=true`) | Variable d'env ou `False` |

#### Param√®tres de configuration (classe ProducerConfig)

Ces param√®tres sont d√©finis dans le code et peuvent √™tre modifi√©s directement dans le script si n√©cessaire :

| Param√®tre | Description | Valeur par d√©faut |
|-----------|-------------|-------------------|
| `bootstrap_servers` | Liste des serveurs Kafka | D√©fini via `--bootstrap-servers` |
| `security_protocol` | Protocole de s√©curit√© | D√©fini via `--security-protocol` ou `KAFKA_SECURITY_PROTOCOL` (d√©faut: `SASL_SSL`) |
| `sasl_mechanism` | M√©canisme SASL | D√©fini via `--sasl-mechanism` ou `KAFKA_SASL_MECHANISM` (d√©faut: `PLAIN`) |
| `sasl_plain_username` | Nom d'utilisateur SASL | D√©fini via `--username` |
| `sasl_plain_password` | Mot de passe SASL | D√©fini via `--password` |
| `topic_prefix` | Pr√©fixe des topics | `test-prometheus` |
| `num_topics` | Nombre de topics | `10` |
| `messages_per_second` | Messages par seconde | `1000` |
| `message_size_kb` | Taille cible des messages en KB | `1` (non utilis√© actuellement) |
| `num_threads` | Nombre de threads | `5` |
| `duration_minutes` | Dur√©e en minutes | `60` |

#### Param√®tres Kafka Producer (cod√©s en dur)

Ces param√®tres sont configur√©s dans la m√©thode `_create_producer()` et peuvent √™tre modifi√©s dans le code :

| Param√®tre | Description | Valeur |
|-----------|-------------|--------|
| `acks` | Confirmation requise (all = tous les replicas) | `'all'` |
| `retries` | Nombre de tentatives en cas d'√©chec | `3` |
| `retry_backoff_ms` | D√©lai entre les tentatives (ms) | `100` |
| `request_timeout_ms` | Timeout des requ√™tes (ms) | `30000` (30s) |
| `max_block_ms` | Temps max d'attente pour obtenir des m√©tadonn√©es (ms) | `10000` (10s) |
| `compression_type` | Type de compression | `'gzip'` |
| `batch_size` | Taille du batch en octets | `16384` (16 KB) |
| `linger_ms` | D√©lai avant envoi du batch (ms) | `10` |
| `buffer_memory` | M√©moire tampon en octets | `33554432` (32 MB) |
| `max_request_size` | Taille max d'une requ√™te en octets | `1048576` (1 MB) |
| `value_serializer` | S√©rialiseur de valeur | JSON encod√© en UTF-8 |
| `key_serializer` | S√©rialiseur de cl√© | UTF-8 (si fournie) |

#### Exemples

**Test rapide (5 minutes, 100 msg/s)**
```bash
python3 kafka_producer_bomber.py \
  --bootstrap-servers kafka1:9092 \
  --username admin \
  --password secret \
  --messages-per-second 100 \
  --duration-minutes 5
```

**Test intensif (1 heure, 5000 msg/s, 20 topics)**
```bash
python3 kafka_producer_bomber.py \
  --bootstrap-servers kafka1:9092,kafka2:9092,kafka3:9092 \
  --username admin \
  --password secret \
  --topic-prefix production-test \
  --num-topics 20 \
  --messages-per-second 5000 \
  --num-threads 10 \
  --duration-minutes 60
```

### Types de messages g√©n√©r√©s

Le script g√©n√®re 5 types de messages diff√©rents :

1. **user_activity** : Activit√© utilisateur (login, logout, navigation, etc.)
2. **system_metrics** : M√©triques syst√®me (CPU, m√©moire, disque, etc.)
3. **transaction** : Transactions financi√®res
4. **log_event** : √âv√©nements de log (DEBUG, INFO, WARN, ERROR, FATAL)
5. **sensor_data** : Donn√©es de capteurs IoT (temp√©rature, humidit√©, etc.)

#### Param√®tres de g√©n√©ration de messages (MessageGenerator)

| Type de donn√©es | Plage de valeurs | Description |
|-----------------|------------------|-------------|
| `user_id` | `user_1` √† `user_100000` | ID utilisateur al√©atoire |
| `session_id` | `session_100000` √† `session_999999` | ID de session |
| `ip_address` | `1.1.1.1` √† `255.255.255.255` | Adresse IP al√©atoire |
| `server_id` | `server_1` √† `server_100` | ID serveur |
| `value` (m√©triques) | `0.0` √† `100.0` | Valeur m√©trique (float) |
| `transaction_id` | `txn_1000000` √† `txn_9999999` | ID transaction |
| `amount` | `1.0` √† `10000.0` | Montant transaction (float) |
| `currency` | `USD`, `EUR`, `GBP`, `JPY` | Devise al√©atoire |
| `level` (logs) | `DEBUG`, `INFO`, `WARN`, `ERROR`, `FATAL` | Niveau de log |
| `sensor_id` | `sensor_1` √† `sensor_1000` | ID capteur |
| `latitude` | `-90.0` √† `90.0` | Latitude (6 d√©cimales) |
| `longitude` | `-180.0` √† `180.0` | Longitude (6 d√©cimales) |
| `altitude` | `0.0` √† `5000.0` | Altitude en m√®tres |

#### M√©tadonn√©es ajout√©es automatiquement

Chaque message g√©n√©r√© inclut automatiquement un champ `_metadata` :
- `generated_at` : Timestamp ISO de g√©n√©ration
- `message_id` : ID unique du message (`msg_1000000` √† `msg_9999999`)
- `version` : Version du format (`1.0`)
- `source` : Source du message (`kafka_producer_bomber`)

### Statistiques affich√©es

Toutes les 10 secondes, le script affiche :
- Nombre de messages envoy√©s
- Nombre de messages √©chou√©s
- Taux de messages par seconde (msg/s)
- D√©bit en MB/s
- Nombre de topics utilis√©s

√Ä la fin de l'ex√©cution, un r√©sum√© complet est affich√© incluant :
- Messages envoy√©s totaux
- Messages √©chou√©s totaux
- Taux moyen (msg/s)
- D√©bit moyen (MB/s)
- Dur√©e totale
- Liste des topics utilis√©s

#### Statistiques collect√©es (ProducerStats)

| M√©trique | Description |
|----------|-------------|
| `messages_sent` | Nombre total de messages envoy√©s avec succ√®s |
| `messages_failed` | Nombre de messages qui ont √©chou√© |
| `bytes_sent` | Nombre total d'octets envoy√©s |
| `start_time` | Timestamp de d√©but d'ex√©cution |
| `topics_created` | Ensemble des topics utilis√©s |

---

## üì• kafka_consumer_bomber.py

### Description

Script qui consomme des messages JSON depuis plusieurs topics Kafka de mani√®re intensive. Il traite les messages avec une simulation de logique m√©tier pour cr√©er une charge r√©aliste sur le cluster et mesurer les performances de consommation.

### Utilisation

#### Commande de base

**Avec fichier .env** (recommand√©) :
```bash
python3 kafka_consumer_bomber.py
```

**Sans fichier .env** :
```bash
python3 kafka_consumer_bomber.py \
  --bootstrap-servers kafka1:9092,kafka2:9092 \
  --username votre_username \
  --password votre_password
```

**M√©lange .env + ligne de commande** (les arguments CLI ont priorit√©) :
```bash
python3 kafka_consumer_bomber.py \
  --num-consumers 3 \
  --duration-minutes 30
```

#### Options disponibles (ligne de commande)

| Option | Description | D√©faut |
|--------|-------------|--------|
| `--bootstrap-servers` | **Requis** (ou via `KAFKA_BOOTSTRAP_SERVERS`). Liste des serveurs Kafka (s√©par√©s par des virgules) | Variable d'env ou - |
| `--username` | **Requis** (ou via `KAFKA_USERNAME`). Nom d'utilisateur SASL PLAIN | Variable d'env ou - |
| `--password` | **Requis** (ou via `KAFKA_PASSWORD`). Mot de passe SASL PLAIN | Variable d'env ou - |
| `--security-protocol` | Protocole de s√©curit√© (ou via `KAFKA_SECURITY_PROTOCOL`) | Variable d'env ou `SASL_SSL` |
| `--sasl-mechanism` | M√©canisme SASL (ou via `KAFKA_SASL_MECHANISM`) | Variable d'env ou `PLAIN` |
| `--topic-prefix` | Pr√©fixe des topics √† consommer (ou via `KAFKA_TOPIC_PREFIX`) | Variable d'env ou `test-prometheus` |
| `--num-topics` | Nombre de topics √† consommer (ou via `KAFKA_NUM_TOPICS`) | Variable d'env ou `10` |
| `--consumer-group` | Groupe de consommateurs (ou via `KAFKA_CONSUMER_GROUP`) | Variable d'env ou `prometheus-test-group` |
| `--num-consumers` | Nombre de consommateurs parall√®les (ou via `KAFKA_NUM_CONSUMERS`) | Variable d'env ou `1` |
| `--duration-minutes` | Dur√©e d'ex√©cution en minutes (ou via `KAFKA_DURATION_MINUTES`) | Variable d'env ou `60` |
| `--auto-offset-reset` | Position de d√©part (ou via `KAFKA_AUTO_OFFSET_RESET`) | Variable d'env ou `earliest` |
| `--ssl-cafile` | Chemin vers le fichier CA SSL (ou via `KAFKA_SSL_CAFILE`) | Variable d'env ou - |
| `--ssl-certfile` | Chemin vers le fichier certificat SSL (ou via `KAFKA_SSL_CERTFILE`) | Variable d'env ou - |
| `--ssl-keyfile` | Chemin vers le fichier cl√© SSL (ou via `KAFKA_SSL_KEYFILE`) | Variable d'env ou - |
| `--ssl-password` | Mot de passe pour la cl√© SSL (ou via `KAFKA_SSL_PASSWORD`) | Variable d'env ou - |
| `--verbose` | Mode verbeux (ou via `KAFKA_VERBOSE=true`) | Variable d'env ou `False` |

#### Param√®tres de configuration (classe ConsumerConfig)

Ces param√®tres sont d√©finis dans le code et peuvent √™tre modifi√©s directement dans le script si n√©cessaire :

| Param√®tre | Description | Valeur par d√©faut |
|-----------|-------------|-------------------|
| `bootstrap_servers` | Liste des serveurs Kafka | D√©fini via `--bootstrap-servers` |
| `security_protocol` | Protocole de s√©curit√© | D√©fini via `--security-protocol` ou `KAFKA_SECURITY_PROTOCOL` (d√©faut: `SASL_SSL`) |
| `sasl_mechanism` | M√©canisme SASL | D√©fini via `--sasl-mechanism` ou `KAFKA_SASL_MECHANISM` (d√©faut: `PLAIN`) |
| `sasl_plain_username` | Nom d'utilisateur SASL | D√©fini via `--username` |
| `sasl_plain_password` | Mot de passe SASL | D√©fini via `--password` |
| `topic_prefix` | Pr√©fixe des topics | `test-prometheus` |
| `num_topics` | Nombre de topics | `10` |
| `consumer_group` | Groupe de consommateurs | `prometheus-test-group` |
| `num_consumers` | Nombre de consommateurs | `5` (mais `1` recommand√©) |
| `duration_minutes` | Dur√©e en minutes | `60` |
| `auto_offset_reset` | Position de d√©part | `earliest` |
| `enable_auto_commit` | Commit automatique des offsets | `True` |
| `max_poll_records` | Nombre max de records par poll | `500` |
| `session_timeout_ms` | Timeout de session (ms) | `30000` (30s) |
| `heartbeat_interval_ms` | Intervalle de heartbeat (ms) | `3000` (3s) |
| `ssl_cafile` | Fichier CA SSL | `None` |
| `ssl_certfile` | Fichier certificat SSL | `None` |
| `ssl_keyfile` | Fichier cl√© SSL | `None` |
| `ssl_password` | Mot de passe cl√© SSL | `None` |

#### Param√®tres Kafka Consumer (cod√©s en dur)

Ces param√®tres sont configur√©s dans la m√©thode `_create_consumer()` et peuvent √™tre modifi√©s dans le code :

| Param√®tre | Description | Valeur |
|-----------|-------------|--------|
| `group.id` | Groupe de consommateurs | D√©fini via `--consumer-group` |
| `auto.offset.reset` | Position de d√©part | D√©fini via `--auto-offset-reset` |
| `enable.auto.commit` | Commit automatique | `True` |
| `session.timeout.ms` | Timeout de session (ms) | `30000` (30s) |
| `heartbeat.interval.ms` | Intervalle de heartbeat (ms) | `3000` (3s) |
| `max.poll.interval.ms` | Intervalle max entre polls (ms) | `300000` (5 min) |
| `fetch.min.bytes` | Nombre min d'octets √† r√©cup√©rer | `1` |
| `fetch.max.wait.ms` | Temps max d'attente pour fetch (ms) | `500` |
| `max.partition.fetch.bytes` | Taille max par partition (octets) | `1048576` (1 MB) |
| `auto.commit.interval.ms` | Intervalle de commit auto (ms) | `1000` (1s) |
| `enable.ssl.certificate.verification` | V√©rification certificat SSL | `False` |
| `ssl.ca.location` | Emplacement CA SSL | D√©fini via `--ssl-cafile` |
| `ssl.certificate.location` | Emplacement certificat SSL | D√©fini via `--ssl-certfile` |
| `ssl.key.location` | Emplacement cl√© SSL | D√©fini via `--ssl-keyfile` |
| `ssl.key.password` | Mot de passe cl√© SSL | D√©fini via `--ssl-password` |

#### Param√®tres de retry et connexion

| Param√®tre | Description | Valeur |
|-----------|-------------|--------|
| `max_retries` | Nombre max de tentatives de connexion | `5` |
| `retry_delay` | D√©lai initial entre tentatives (secondes) | `3` |
| `consumer_startup_delay` | D√©lai entre d√©marrage des consommateurs (secondes) | `1.0` par consumer_id |
| `poll_timeout` | Timeout du poll (secondes) | `1.0` |
| `stats_report_interval` | Intervalle de rapport des stats (secondes) | `10` |

#### Exemples

**Consommation basique**
```bash
python3 kafka_consumer_bomber.py \
  --bootstrap-servers kafka1:9092 \
  --username admin \
  --password secret \
  --duration-minutes 30
```

**Consommation intensive (plusieurs consommateurs)**
```bash
python3 kafka_consumer_bomber.py \
  --bootstrap-servers kafka1:9092,kafka2:9092 \
  --username admin \
  --password secret \
  --topic-prefix production-test \
  --num-topics 20 \
  --consumer-group test-group-1 \
  --num-consumers 3 \
  --duration-minutes 60
```

**Avec certificats SSL personnalis√©s**
```bash
python3 kafka_consumer_bomber.py \
  --bootstrap-servers kafka1:9092 \
  --username admin \
  --password secret \
  --ssl-cafile /path/to/ca.pem \
  --ssl-certfile /path/to/cert.pem \
  --ssl-keyfile /path/to/key.pem \
  --ssl-password key_password
```

### Traitement des messages

Le script simule un traitement complet des messages :
- **Validation** : V√©rifie la structure et le format des messages
- **Transformation** : Normalise et enrichit les donn√©es
- **Logique m√©tier** : Traite diff√©remment selon le type de message
- **D√©lai de traitement** : Simule un temps de traitement r√©aliste (1-50ms)

#### Param√®tres de traitement (MessageProcessor)

| Param√®tre | Description | Valeur |
|-----------|-------------|--------|
| `processing_delay_min` | D√©lai min de traitement (secondes) | `0.001` (1ms) |
| `processing_delay_max` | D√©lai max de traitement (secondes) | `0.050` (50ms) |
| `required_fields` | Champs requis dans les messages | `["timestamp", "_metadata"]` |
| `stats_report_interval` | Intervalle de rapport des stats (secondes) | `10` |

#### Types de messages trait√©s

Le script traite diff√©remment selon le type de message :

1. **user_activity** : Analyse de comportement utilisateur (login/logout)
2. **system_metrics** : Analyse de performance (seuil d'alerte √† 80)
3. **transaction** : Validation de transaction (seuil important √† 1000)
4. **log_event** : Analyse de logs (alertes pour ERROR/FATAL)
5. **sensor_data** : Analyse de donn√©es IoT (alertes pour qualit√© "poor")

### Statistiques affich√©es

Toutes les 10 secondes, le script affiche :
- Nombre de messages consomm√©s
- Nombre de messages √©chou√©s
- Taux de messages par seconde (msg/s)
- D√©bit en MB/s
- Nombre de messages trait√©s
- Taux d'erreur de traitement
- Topics actifs

√Ä la fin de l'ex√©cution, un r√©sum√© d√©taill√© est affich√© incluant :
- Statistiques globales
- R√©partition par type de message
- R√©partition par topic

#### Statistiques collect√©es (ConsumerStats)

| M√©trique | Description |
|----------|-------------|
| `messages_consumed` | Nombre total de messages consomm√©s |
| `messages_failed` | Nombre de messages qui ont √©chou√© |
| `bytes_consumed` | Nombre total d'octets consomm√©s |
| `start_time` | Timestamp de d√©but d'ex√©cution |
| `consumer_lag` | Lag par partition (dictionnaire) |

#### Statistiques de traitement (MessageProcessor Stats)

| M√©trique | Description |
|----------|-------------|
| `messages_processed` | Nombre de messages trait√©s avec succ√®s |
| `processing_errors` | Nombre d'erreurs de traitement |
| `bytes_processed` | Nombre total d'octets trait√©s |
| `avg_processing_time_ms` | Temps moyen de traitement (ms) |
| `messages_by_type` | R√©partition par type de message |
| `messages_by_topic` | R√©partition par topic |
| `error_rate` | Taux d'erreur (erreurs / messages trait√©s) |

---

## üîÑ Utilisation combin√©e

Pour un test complet, vous pouvez lancer les deux scripts simultan√©ment :

**Terminal 1 - Producteur**
```bash
python3 kafka_producer_bomber.py \
  --bootstrap-servers kafka1:9092 \
  --username admin \
  --password secret \
  --messages-per-second 2000 \
  --duration-minutes 60
```

**Terminal 2 - Consommateur**
```bash
python3 kafka_consumer_bomber.py \
  --bootstrap-servers kafka1:9092 \
  --username admin \
  --password secret \
  --num-consumers 2 \
  --duration-minutes 60
```

---

## üîß Personnalisation avanc√©e

### Modification des param√®tres cod√©s en dur

Pour modifier les param√®tres qui ne sont pas expos√©s via la ligne de commande, vous pouvez √©diter directement les scripts :

#### Dans `kafka_producer_bomber.py`

**Modifier les param√®tres du producteur Kafka** (ligne ~233-250) :
```python
producer = KafkaProducer(
    # ... autres param√®tres ...
    acks='all',                    # Modifier pour '0' ou '1' si besoin
    retries=3,                     # Augmenter pour plus de r√©silience
    compression_type='gzip',       # Changer en 'snappy' ou 'lz4'
    batch_size=16384,              # Ajuster selon la taille des messages
    linger_ms=10,                  # Augmenter pour plus de batching
    buffer_memory=33554432,        # Augmenter pour plus de throughput
)
```

**Modifier les templates de messages** (ligne ~52-130) :
- Ajouter de nouveaux types de messages dans `_create_message_templates()`
- Modifier les plages de valeurs dans `generate_random_data()`

#### Dans `kafka_consumer_bomber.py`

**Modifier les param√®tres du consommateur Kafka** (ligne ~239-257) :
```python
consumer_config = {
    # ... autres param√®tres ...
    'max.poll.interval.ms': 300000,      # Augmenter si traitement long
    'fetch.min.bytes': 1,                # Augmenter pour moins de requ√™tes
    'fetch.max.wait.ms': 500,            # Augmenter pour plus de batching
    'max.partition.fetch.bytes': 1048576, # Augmenter pour plus de donn√©es
    'auto.commit.interval.ms': 1000,     # Ajuster selon besoins
}
```

**Modifier la logique de traitement** (ligne ~65-189) :
- Personnaliser `_simulate_processing()` pour votre cas d'usage
- Modifier les seuils d'alerte dans les m√©thodes `_process_*()`
- Ajuster les d√©lais de traitement dans `_simulate_processing()`

### Variables d'environnement

Les scripts supportent maintenant les variables d'environnement via un fichier `.env` (voir section [Configuration via fichier .env](#configuration-via-fichier-env-recommand√©)).

Avantages :
- ‚úÖ Stocker les credentials de mani√®re s√©curis√©e (ajoutez `.env` √† `.gitignore`)
- ‚úÖ Configurer les param√®tres par d√©faut
- ‚úÖ G√©rer diff√©rents environnements (dev, staging, prod) avec diff√©rents fichiers `.env`
- ‚úÖ √âviter d'exposer les credentials dans l'historique de commandes

Les param√®tres pass√©s en ligne de commande ont toujours priorit√© sur les variables d'environnement.

## ‚ö†Ô∏è Notes importantes

### Conflits SSL

Le script `kafka_consumer_bomber.py` peut rencontrer des conflits SSL lors de la cr√©ation de plusieurs consommateurs simultan√©ment. Par d√©faut, `--num-consumers` est r√©gl√© √† `1` pour √©viter ces probl√®mes. Si vous devez utiliser plusieurs consommateurs, augmentez progressivement et surveillez les logs.

### Format des topics

Les scripts cr√©ent/consomment des topics au format :
```
{prefix}.generated-data-{num:02d}.json
```

Par exemple, avec le pr√©fixe par d√©faut `test-prometheus` et 10 topics :
- `test-prometheus.generated-data-01.json`
- `test-prometheus.generated-data-02.json`
- ...
- `test-prometheus.generated-data-10.json`

### Arr√™t propre

Les scripts g√®rent les signaux `SIGINT` (Ctrl+C) et `SIGTERM` pour un arr√™t propre. Ils afficheront les statistiques finales avant de se terminer.

### Performance

Pour des tests de performance optimaux :
- Ajustez `--messages-per-second` selon la capacit√© de votre cluster
- Utilisez `--num-threads` (producteur) pour parall√©liser l'envoi
- Utilisez `--num-consumers` (consommateur) avec pr√©caution (voir note SSL)
- Surveillez les m√©triques Prometheus pendant l'ex√©cution
- Ajustez `batch_size` et `linger_ms` dans le producteur pour optimiser le throughput
- Ajustez `fetch.min.bytes` et `fetch.max.wait.ms` dans le consommateur pour r√©duire la charge r√©seau

### S√©curit√©

**Recommandations importantes** :

1. **Utilisez un fichier `.env`** au lieu de passer les credentials en ligne de commande :
   - Les credentials en ligne de commande sont visibles dans `ps` et l'historique shell
   - Le fichier `.env` peut √™tre prot√©g√© avec des permissions restrictives (`chmod 600 .env`)

2. **Ajoutez `.env` √† `.gitignore`** :
   ```bash
   echo ".env" >> .gitignore
   ```

3. **Certificats SSL** :
   - Utilisez les certificats SSL pour une s√©curit√© renforc√©e
   - Le param√®tre `enable.ssl.certificate.verification` est d√©sactiv√© par d√©faut (√† activer en production)

4. **Permissions du fichier .env** :
   ```bash
   chmod 600 .env  # Lecture/√©criture uniquement pour le propri√©taire
   ```

5. **Variables d'environnement syst√®me** :
   - Vous pouvez aussi d√©finir les variables directement dans votre shell :
     ```bash
     export KAFKA_USERNAME=admin
     export KAFKA_PASSWORD=secret
     ```
   - Cela √©vite m√™me d'avoir un fichier `.env` sur le disque

---

## üêõ D√©pannage

### Erreur de connexion

V√©rifiez :
- Les serveurs Kafka sont accessibles
- Les credentials sont corrects
- Le protocole de s√©curit√© correspond √† votre configuration Kafka

### Messages non re√ßus (consommateur)

V√©rifiez :
- Les topics existent et contiennent des messages
- Le `--auto-offset-reset` est correct (`earliest` pour lire depuis le d√©but)
- Le groupe de consommateurs n'est pas d√©j√† utilis√© ailleurs

### Performance faible

- Augmentez `--num-threads` pour le producteur
- V√©rifiez la charge r√©seau et CPU
- Surveillez les m√©triques Kafka (lag, throughput)

---

## üìä Int√©gration avec Prometheus

Ces scripts sont con√ßus pour g√©n√©rer du trafic Kafka qui sera monitor√© par Prometheus via les exporters JMX. Les m√©triques suivantes seront particuli√®rement int√©ressantes √† surveiller :

- **Producteur** : `kafka_producer_*` (taux d'envoi, latence, erreurs)
- **Consommateur** : `kafka_consumer_*` (lag, throughput, commit rate)
- **Broker** : `kafka_server_*` (bytes in/out, requests, partitions)

Les dashboards Grafana fournis dans ce projet visualisent ces m√©triques.

---

## üê≥ Utilisation avec Docker

### Construction de l'image

```bash
cd kafka-consumer-producer
docker build -t kafka-perf-test:latest .
```

### Utilisation interactive (recommand√©)

L'entr√©e par d√©faut lance un shell interactif pour que vous puissiez ex√©cuter les commandes manuellement :

```bash
# Cr√©er le fichier .env d'abord
cp env.example .env
# √âditer .env avec vos credentials

# Entrer dans le conteneur interactif
docker run -it --rm \
  -v $(pwd)/.env:/app/.env:ro \
  --network host \
  kafka-perf-test:latest

# Depuis le conteneur, vous pouvez maintenant lancer:
python3 /app/kafka_producer_bomber.py --help
python3 /app/kafka_consumer_bomber.py --help

# Ou utiliser les alias disponibles:
producer-bomber --help
consumer-bomber --help
kafka-producer-perf --help
kafka-consumer-perf --help
```

### Utilisation directe (sans shell interactif)

Vous pouvez aussi lancer directement les commandes :

```bash
# Lancer le producteur directement
docker run --rm \
  -v $(pwd)/.env:/app/.env:ro \
  --network host \
  kafka-perf-test:latest \
  producer-bomber

# Lancer le consommateur directement
docker run --rm \
  -v $(pwd)/.env:/app/.env:ro \
  --network host \
  kafka-perf-test:latest \
  consumer-bomber
```

#### Avec variables d'environnement

```bash
docker run --rm \
  -e KAFKA_BOOTSTRAP_SERVERS=kafka1:9092 \
  -e KAFKA_USERNAME=admin \
  -e KAFKA_PASSWORD=secret \
  --network host \
  kafka-perf-test:latest \
  producer-bomber \
  --messages-per-second 2000 \
  --duration-minutes 30
```

### Utilisation des outils Kafka perf test

#### Producer perf test

```bash
# Avec fichier de configuration (recommand√© pour SASL)
docker run --rm \
  -v $(pwd)/config/producer.properties:/app/config/producer.properties:ro \
  --network host \
  kafka-perf-test:latest \
  kafka-producer-perf \
  --topic test-topic \
  --num-records 100000 \
  --record-size 1024 \
  --throughput 10000 \
  --producer-props config-file=/app/config/producer.properties

# Ou avec propri√©t√©s inline (moins s√©curis√©)
docker run --rm \
  --network host \
  kafka-perf-test:latest \
  kafka-producer-perf \
  --topic test-topic \
  --num-records 100000 \
  --record-size 1024 \
  --throughput 10000 \
  --producer-props bootstrap.servers=kafka1:9092,security.protocol=SASL_SSL,sasl.mechanism=PLAIN,sasl.jaas.config="org.apache.kafka.common.security.plain.PlainLoginModule required username=\"admin\" password=\"secret\";"
```

#### Consumer perf test

```bash
# Avec fichier de configuration (recommand√© pour SASL)
docker run --rm \
  -v $(pwd)/config/consumer.properties:/app/config/consumer.properties:ro \
  --network host \
  kafka-perf-test:latest \
  kafka-consumer-perf \
  --topic test-topic \
  --messages 100000 \
  --consumer.config /app/config/consumer.properties
```

**Note** : Des fichiers d'exemple sont fournis dans `config/consumer.properties.example` et `config/producer.properties.example`. Copiez-les et modifiez-les selon vos besoins.

### Utilisation avec docker-compose

Un fichier `docker-compose.test.yml` est fourni pour faciliter l'utilisation :

```bash
# Construire l'image
docker-compose -f docker-compose.test.yml build

# Entrer dans le conteneur interactif
docker-compose -f docker-compose.test.yml run --rm kafka-perf-test bash

# Ou lancer directement une commande
docker-compose -f docker-compose.test.yml run --rm kafka-perf-test producer-bomber
docker-compose -f docker-compose.test.yml run --rm kafka-perf-test consumer-bomber
docker-compose -f docker-compose.test.yml run --rm kafka-perf-test \
  kafka-producer-perf --topic test --num-records 10000 --record-size 1024 \
  --producer-props bootstrap.servers=kafka1:9092
```

### Commandes disponibles

Dans le conteneur, les alias suivants sont disponibles :

| Alias | Commande r√©elle | Description |
|-------|----------------|-------------|
| `producer-bomber` | `python3 /app/kafka_producer_bomber.py` | Script bomber producteur Python |
| `consumer-bomber` | `python3 /app/kafka_consumer_bomber.py` | Script bomber consommateur Python |
| `kafka-producer-perf` | `${KAFKA_HOME}/bin/kafka-producer-perf-test.sh` | Outil perf test producteur Kafka officiel |
| `kafka-consumer-perf` | `${KAFKA_HOME}/bin/kafka-consumer-perf-test.sh` | Outil perf test consommateur Kafka officiel |

Vous pouvez aussi utiliser les chemins complets directement :
- `/app/kafka_producer_bomber.py`
- `/app/kafka_consumer_bomber.py`
- `${KAFKA_HOME}/bin/kafka-producer-perf-test.sh`
- `${KAFKA_HOME}/bin/kafka-consumer-perf-test.sh`

### Configuration r√©seau

Si vos brokers Kafka sont accessibles depuis l'h√¥te, utilisez `--network host` :

```bash
docker run --rm --network host kafka-perf-test:latest producer-bomber
```

Si vous utilisez un r√©seau Docker personnalis√©, connectez le conteneur au r√©seau appropri√© :

```bash
docker run --rm --network monitoring kafka-perf-test:latest producer-bomber
```

### Montage de certificats SSL

Si vous utilisez des certificats SSL personnalis√©s :

```bash
docker run --rm \
  -v $(pwd)/.env:/app/.env:ro \
  -v $(pwd)/certs:/app/certs:ro \
  --network host \
  kafka-perf-test:latest \
  producer-bomber \
  --ssl-cafile /app/certs/ca.pem \
  --ssl-certfile /app/certs/cert.pem \
  --ssl-keyfile /app/certs/key.pem
```

---

## üìã Tableau r√©capitulatif des param√®tres

### kafka_producer_bomber.py

| Cat√©gorie | Param√®tre | CLI | Valeur par d√©faut | Modifiable |
|-----------|-----------|-----|-------------------|-----------|
| **Connexion** | `bootstrap_servers` | `--bootstrap-servers` | - | ‚úÖ |
| | `security_protocol` | `--security-protocol` | `SASL_SSL` | ‚úÖ |
| | `sasl_mechanism` | `--sasl-mechanism` | `PLAIN` | ‚úÖ |
| | `sasl_plain_username` | `--username` | - | ‚úÖ |
| | `sasl_plain_password` | `--password` | - | ‚úÖ |
| **Topics** | `topic_prefix` | `--topic-prefix` | `test-prometheus` | ‚úÖ |
| | `num_topics` | `--num-topics` | `10` | ‚úÖ |
| **Performance** | `messages_per_second` | `--messages-per-second` | `1000` | ‚úÖ |
| | `num_threads` | `--num-threads` | `5` | ‚úÖ |
| | `batch_size` | - | `16384` | Code |
| | `linger_ms` | - | `10` | Code |
| | `buffer_memory` | - | `33554432` | Code |
| | `compression_type` | - | `gzip` | Code |
| **Dur√©e** | `duration_minutes` | `--duration-minutes` | `60` | ‚úÖ |
| **Logs** | `verbose` | `--verbose` | `False` | ‚úÖ |

### kafka_consumer_bomber.py

| Cat√©gorie | Param√®tre | CLI | Valeur par d√©faut | Modifiable |
|-----------|-----------|-----|-------------------|-----------|
| **Connexion** | `bootstrap_servers` | `--bootstrap-servers` | - | ‚úÖ |
| | `security_protocol` | `--security-protocol` | `SASL_SSL` | ‚úÖ |
| | `sasl_mechanism` | `--sasl-mechanism` | `PLAIN` | ‚úÖ |
| | `sasl_plain_username` | `--username` | - | ‚úÖ |
| | `sasl_plain_password` | `--password` | - | ‚úÖ |
| **SSL** | `ssl_cafile` | `--ssl-cafile` | `None` | ‚úÖ |
| | `ssl_certfile` | `--ssl-certfile` | `None` | ‚úÖ |
| | `ssl_keyfile` | `--ssl-keyfile` | `None` | ‚úÖ |
| | `ssl_password` | `--ssl-password` | `None` | ‚úÖ |
| **Topics** | `topic_prefix` | `--topic-prefix` | `test-prometheus` | ‚úÖ |
| | `num_topics` | `--num-topics` | `10` | ‚úÖ |
| **Consumer** | `consumer_group` | `--consumer-group` | `prometheus-test-group` | ‚úÖ |
| | `num_consumers` | `--num-consumers` | `1` | ‚úÖ |
| | `auto_offset_reset` | `--auto-offset-reset` | `earliest` | ‚úÖ |
| | `enable_auto_commit` | - | `True` | Code |
| | `max_poll_records` | - | `500` | Code |
| | `session_timeout_ms` | - | `30000` | Code |
| | `heartbeat_interval_ms` | - | `3000` | Code |
| | `max_poll_interval_ms` | - | `300000` | Code |
| | `fetch.min.bytes` | - | `1` | Code |
| | `fetch.max.wait.ms` | - | `500` | Code |
| **Dur√©e** | `duration_minutes` | `--duration-minutes` | `60` | ‚úÖ |
| **Logs** | `verbose` | `--verbose` | `False` | ‚úÖ |

**L√©gende :**
- ‚úÖ = Modifiable via ligne de commande
- Code = N√©cessite modification du code source

---

## üîç Limites et contraintes

### Limites connues

1. **Conflits SSL** : Le consommateur peut rencontrer des probl√®mes avec plusieurs consommateurs simultan√©s
2. **Taille des messages** : Les messages sont g√©n√©r√©s avec une taille variable (pas de contr√¥le strict)
3. **Retry limit√©** : Maximum 5 tentatives de connexion pour le consommateur
4. **Pas de gestion de partition** : Les scripts ne g√®rent pas explicitement les partitions
5. **Pas de gestion d'erreurs avanc√©e** : Les erreurs sont logg√©es mais pas toutes g√©r√©es de mani√®re sp√©cifique

### Recommandations

- **Producteur** : Commencez avec `--num-threads=5` et augmentez progressivement
- **Consommateur** : Utilisez `--num-consumers=1` par d√©faut pour √©viter les conflits SSL
- **Topics** : Cr√©ez les topics manuellement si n√©cessaire avant d'ex√©cuter les scripts
- **Monitoring** : Surveillez les m√©triques Kafka pendant l'ex√©cution pour d√©tecter les probl√®mes
